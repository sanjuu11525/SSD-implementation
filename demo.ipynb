{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD PyTorch Demostration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module\n",
    "First of all, import necessary modules and set hardware device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7919,
     "status": "ok",
     "timestamp": 1535135650959,
     "user": {
      "displayName": "sanjuu11525",
      "photoUrl": "//lh3.googleusercontent.com/-b_X1gHwefAw/AAAAAAAAAAI/AAAAAAAAAdc/aBa0PceAYvI/s50-c-k-no/photo.jpg",
      "userId": "112340299355919007738"
     },
     "user_tz": -120
    },
    "id": "lDW8dw56_sNV",
    "outputId": "44dc12f0-bd53-443b-dfbe-b3edbc30146b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"PyTorch version: \" + str(torch.__version__))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device.__str__() + \": \" + torch.version.cuda + \" available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the parameter set for data loading\n",
    "One example is provided for the reader. Those parameters can be rewritten for initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc2007_12 import VOCDataBase\n",
    "\n",
    "dataset_parameter = {\n",
    "    'root' : None, 'image_set' : \"trainval\", 'year' : None,\n",
    "    'transforms' : None, 'keep_difficult' : False, 'mean' : [104., 117., 123.]\n",
    "}\n",
    "dataset_parameter['train_transforms'] = transforms.Compose([transforms.ToTensor()])\n",
    "dataset_parameter['root'] = \"./VOCdevkit\"\n",
    "dataset_parameter['year'] = \"2012\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data class\n",
    "The function, collate, specifies how data packed for the dataloader with batch size. The reader can move it away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2568,
     "status": "ok",
     "timestamp": 1535135667648,
     "user": {
      "displayName": "sanjuu11525",
      "photoUrl": "//lh3.googleusercontent.com/-b_X1gHwefAw/AAAAAAAAAAI/AAAAAAAAAdc/aBa0PceAYvI/s50-c-k-no/photo.jpg",
      "userId": "112340299355919007738"
     },
     "user_tz": -120
    },
    "id": "NQdEO4Gio_xi",
    "outputId": "fb4365b2-be9c-47fa-c138-70722b4a6dd1"
   },
   "outputs": [],
   "source": [
    " def collate(batch):\n",
    "    \"\"\"Customized collate function for detection-oriented applications.The packed/return is expected \n",
    "       by the iterator of training, and the iterator of unpacked/argument here depends on VOCDataBase.__getitem__.\n",
    "    Arguments:\n",
    "      batch: (tuple) A tuple of tensor images and lists of annotations.\n",
    "    Return:\n",
    "        1) a stack of frames: (tensor), sized [#batch,3, 300, 300].     \n",
    "        2) gt_boxes:  (list) annotations for a given image, length: #batch\n",
    "        3) gt_labels: (list) annotations for a given image, length: #batch\n",
    "    \"\"\"\n",
    "    gt_boxes = []\n",
    "    frames = []\n",
    "    gt_labels = []\n",
    "    for image, boxes, labels in batch:\n",
    "        gt_labels.append(labels)\n",
    "        frames.append(image)\n",
    "        gt_boxes.append(boxes)\n",
    "    return torch.stack(frames, 0), (gt_boxes, gt_labels)\n",
    "\n",
    "train_data = VOCDataBase(dataset_parameter)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=False, collate_fn = collate, num_workers=1)\n",
    "train_data.showGroundTruth(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG pretraining \n",
    "Load the vgg model from the refernce[1] of github page. Then, again the parameter set is for the training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssd import SSD\n",
    "model_local_path = './weights/vgg16_reducedfc.pth'\n",
    "pre_train_vgg = torch.load(model_local_path)\n",
    "model = SSD(pre_train_vgg)\n",
    "\n",
    "train_parameter = {\n",
    "    'n_epoch' : 9, 'learning_rate' : 1e-4, 'weight_decay' : 5e-4, 'momentum' : 0.9,\n",
    "    'milestones' : None, 'gamma' : 0.1, 'device' : None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "Training on the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3750
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9878318,
     "status": "ok",
     "timestamp": 1534888854886,
     "user": {
      "displayName": "sanjuu11525",
      "photoUrl": "//lh3.googleusercontent.com/-b_X1gHwefAw/AAAAAAAAAAI/AAAAAAAAAdc/aBa0PceAYvI/s50-c-k-no/photo.jpg",
      "userId": "112340299355919007738"
     },
     "user_tz": -120
    },
    "id": "tkJD_90F9_ut",
    "outputId": "a83980db-fef6-4091-ee39-841a2598fb29"
   },
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "\n",
    "loss_total, loss_conf_out, loss_loc_out = [], [], []\n",
    "train_parameter['device'] = device\n",
    "train = Trainer(train_parameter, model)\n",
    "train.train(loss_total, loss_conf_out, loss_loc_out, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1534888883852,
     "user": {
      "displayName": "sanjuu11525",
      "photoUrl": "//lh3.googleusercontent.com/-b_X1gHwefAw/AAAAAAAAAAI/AAAAAAAAAdc/aBa0PceAYvI/s50-c-k-no/photo.jpg",
      "userId": "112340299355919007738"
     },
     "user_tz": -120
    },
    "id": "njMP0il7YB_3",
    "outputId": "c8154344-7afd-44f7-cd64-d74d668e36f0"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_total)\n",
    "plt.plot(loss_conf_out)\n",
    "plt.plot(loss_loc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Initialize evaluation data/loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc2007_12 import VOCDataBase\n",
    "\n",
    "dataset_parameter = {\n",
    "    'root' : None, 'image_set' : \"trainval\", 'year' : None,\n",
    "    'transforms' : None, 'keep_difficult' : False, 'mean' : [104., 117., 123.]\n",
    "}\n",
    "dataset_parameter['train_transforms'] = transforms.Compose([transforms.ToTensor()])\n",
    "dataset_parameter['root'] = \"./VOCdevkit\"\n",
    "dataset_parameter['year'] = \"2007\"\n",
    "dataset_parameter['image_set'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = VOCDataBase(dataset_parameter)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_data, batch_size=1, shuffle=False, collate_fn = detection_collate, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import Evaluation\n",
    "\n",
    "eval_parameter = {'device' : None }\n",
    "eval_parameter['device'] = device\n",
    "eval_ = Evaluation(eval_parameter, model)\n",
    "eval_.evaluate(model, eval_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SSD.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
